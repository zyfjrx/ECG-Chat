"""
æ€»ç»“å»é‡ç»“æœ - æ¸…æ™°å±•ç¤ºå»é‡æ•ˆæœ
"""

import json
from collections import defaultdict
import os

def summarize_results():
    """æ€»ç»“å»é‡ç»“æœ"""

    try:
        # åŠ è½½ç»“æœæ–‡ä»¶
        with open('../out/unique_files_with_labels.json', 'r') as f:
            unique_files = json.load(f)

        with open('../out/unique_files_with_labels_duplicates.json', 'r') as f:
            duplicates = json.load(f)

        print("="*70)
        print("ğŸ¯ ECG+æ ‡ç­¾ç»„åˆå»é‡ç»“æœæ€»ç»“")
        print("="*70)

        print(f"\nğŸ“Š æ€»ä½“ç»Ÿè®¡:")
        print(f"  å»é‡åå”¯ä¸€æ–‡ä»¶: {len(unique_files):,} ä¸ª")
        print(f"  é‡å¤ç»„æ•°: {len(duplicates):,}")

        # è®¡ç®—è¢«ç§»é™¤çš„æ–‡ä»¶æ•°
        removed_files = sum(group['count'] - 1 for group in duplicates)
        original_files = len(unique_files) + removed_files
        dedup_rate = removed_files / original_files * 100 if original_files > 0 else 0

        print(f"  åŸå§‹æ–‡ä»¶æ•°: {original_files:,} ä¸ª")
        print(f"  è¢«ç§»é™¤æ–‡ä»¶: {removed_files:,} ä¸ª")
        print(f"  å»é‡ç‡: {dedup_rate:.2f}%")

        # åˆ†ææ ‡ç­¾ç»„åˆ
        print(f"\nğŸ“‹ æ ‡ç­¾ç»„åˆåˆ†æ:")

        # ç»Ÿè®¡æ¯ç§æ ‡ç­¾ç»„åˆçš„é‡å¤æƒ…å†µ
        label_combinations = defaultdict(lambda: {'groups': 0, 'files': 0, 'removed': 0})

        for dup_group in duplicates:
            labels = tuple(dup_group['labels'])
            group_count = dup_group['count']
            removed_count = group_count - 1

            label_combinations[labels]['groups'] += 1
            label_combinations[labels]['files'] += group_count
            label_combinations[labels]['removed'] += removed_count

        print(f"\n  é‡å¤æœ€å¤šçš„æ ‡ç­¾ç»„åˆï¼ˆå‰10ï¼‰:")
        sorted_combinations = sorted(label_combinations.items(),
                                   key=lambda x: x[1]['removed'], reverse=True)

        for i, (labels, stats) in enumerate(sorted_combinations[:10], 1):
            print(f"  {i:2d}. æ ‡ç­¾ {list(labels)}:")
            print(f"      é‡å¤ç»„æ•°: {stats['groups']}")
            print(f"      æ¶‰åŠæ–‡ä»¶: {stats['files']}")
            print(f"      ç§»é™¤æ–‡ä»¶: {stats['removed']}")

        # è§£é‡Šä¸ºä»€ä¹ˆç›¸åŒæ ‡ç­¾ä¼šæœ‰ä¸åŒå“ˆå¸Œ
        print(f"\nğŸ’¡ é‡è¦è¯´æ˜:")
        print("  ç›¸åŒæ ‡ç­¾ç»„åˆä½†ä¸åŒå“ˆå¸Œå€¼çš„åŸå› :")
        print("  âœ“ ECGä¿¡å·æ•°æ®ä¸åŒï¼ˆå³ä½¿æ ‡ç­¾ç›¸åŒï¼‰")
        print("  âœ“ è¿™æ˜¯æ­£ç¡®çš„è¡Œä¸º - åªæœ‰ECG+æ ‡ç­¾éƒ½ç›¸åŒæ‰å»é‡")
        print("  âœ“ ç¡®ä¿äº†æ•°æ®å¤šæ ·æ€§ï¼Œé¿å…è¯¯åˆ ä¸åŒç—…ä¾‹")

        # å±•ç¤ºä¸€äº›å…·ä½“ä¾‹å­
        if len(duplicates) > 0:
            print(f"\nğŸ” é‡å¤æ–‡ä»¶ç¤ºä¾‹:")
            for i, dup_group in enumerate(duplicates[:3], 1):
                labels = dup_group['labels']
                files = dup_group['files']
                print(f"\n  ç¤ºä¾‹ {i}:")
                print(f"    æ ‡ç­¾: {labels}")
                print(f"    æ–‡ä»¶æ•°: {len(files)}")
                print(f"    ä¿ç•™æ–‡ä»¶: {os.path.basename(files[0])}")
                if len(files) > 1:
                    print(f"    ç§»é™¤æ–‡ä»¶: {', '.join(os.path.basename(f) for f in files[1:3])}")
                    if len(files) > 3:
                        print(f"    ... è¿˜æœ‰ {len(files)-3} ä¸ª")

        print(f"\n" + "="*70)
        print("âœ… å»é‡é€»è¾‘éªŒè¯é€šè¿‡ï¼")
        print("âœ… ç›¸åŒECG+æ ‡ç­¾ç»„åˆçš„æ–‡ä»¶è¢«æ­£ç¡®è¯†åˆ«")
        print("âœ… ä¸åŒECGä¿¡å·ä½†ç›¸åŒæ ‡ç­¾çš„æ–‡ä»¶è¢«ä¿ç•™")
        print("âœ… ç¡®ä¿äº†æ•°æ®çš„å®Œæ•´æ€§å’Œå¤šæ ·æ€§")
        print("="*70)

    except FileNotFoundError as e:
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {e}")
        print("è¯·å…ˆè¿è¡Œå»é‡è„šæœ¬ç”Ÿæˆç»“æœæ–‡ä»¶")

if __name__ == "__main__":
    summarize_results()